{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "95ea6e43-4a03-4be2-8df5-88b0f1d02a43",
      "metadata": {
        "id": "95ea6e43-4a03-4be2-8df5-88b0f1d02a43"
      },
      "source": [
        "* Tensors are arrays that are the building blocks of a neural network.\n",
        "* objectives:-\n",
        "1. Data types\n",
        "2. Indexing and slicing\n",
        "3. Basic operations\n",
        "4. Universal functions\n",
        "\n",
        "* Basics:-\n",
        "1. 0-dimensional is just a number\n",
        "2. 1-dimensional is array of number eg:- row in database, a vector and timeseries data\n",
        "\n",
        "* We can create a tensor in the following manner:\n",
        "1. First, we import torch. Next, we create a python list with the following elements 7,4,3,2,6.\n",
        "2. We then cast this list to a pytorch tensor using the constructor for tensors.\n",
        "3. We can access the data via an index in the tensor.\n",
        "4. As with a lists, we can access each element with an integer and a square bracket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3fa4c0d-318c-43d9-b59d-590780b0d9f9",
      "metadata": {
        "id": "c3fa4c0d-318c-43d9-b59d-590780b0d9f9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ebb6546-8f68-4674-8532-e2679c7c1564",
      "metadata": {
        "id": "7ebb6546-8f68-4674-8532-e2679c7c1564",
        "outputId": "f21ef773-3baf-4da6-e58e-23dcdb2abc99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([7, 4, 3, 2, 6])\n",
            "torch.int64\n",
            "torch.LongTensor\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([7,4,3,2,6])\n",
        "print(a)\n",
        "print(a.dtype)\n",
        "print(a.type())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7210bf71-b2b1-4ae5-8ba3-5ca9b46be232",
      "metadata": {
        "id": "7210bf71-b2b1-4ae5-8ba3-5ca9b46be232",
        "outputId": "eb6efdbf-981d-4696-9770-0730f1af14f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6], dtype=torch.int32)\n",
            "torch.IntTensor\n"
          ]
        }
      ],
      "source": [
        "#We can also specify the datatype of a tensor with the constructor.We can specify the data type using the parameter d type\n",
        "b=torch.tensor([0.0,1.0,2.0,3.0,4.0,5.0,6.0], dtype=torch.int32)\n",
        "print(b)\n",
        "print(b.type())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4184a97-d29e-4531-ac09-762497db9b94",
      "metadata": {
        "id": "d4184a97-d29e-4531-ac09-762497db9b94",
        "outputId": "fe1c9624-d9d3-40ce-cafe-bb446263d730"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 2., 3., 4.])\n",
            "torch.FloatTensor\n"
          ]
        }
      ],
      "source": [
        "#We can also explicitly create a tensor of a specific type,in this example we create a float tensor explicitly using the FloatTensor method\n",
        "c=torch.FloatTensor([0,1,2,3,4])\n",
        "print(c)\n",
        "print(c.type())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71c54cd-11d8-4443-8617-eefaaf28b10a",
      "metadata": {
        "id": "a71c54cd-11d8-4443-8617-eefaaf28b10a",
        "outputId": "568e1a4b-6b77-43c5-d2b1-9a6289099230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.FloatTensor\n"
          ]
        }
      ],
      "source": [
        "#We can convert the type of the tensor to float using the type method, passing in the argument torch.FloatTensor\n",
        "a=a.type(torch.FloatTensor)\n",
        "print(a.type())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d417422f-b19e-451f-940f-3f7a5c0db7f3",
      "metadata": {
        "id": "d417422f-b19e-451f-940f-3f7a5c0db7f3",
        "outputId": "334eb3df-4b48-4e32-f861-ddccc9947783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5])\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "#We can cast the following list to a tensor. The method size gives us the number of elements in the tensor.\n",
        "print(a.size())\n",
        "print(a.ndimension())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8916f408-6250-4c57-964d-63b986fbe668",
      "metadata": {
        "id": "8916f408-6250-4c57-964d-63b986fbe668",
        "outputId": "ca2f0ca6-e384-4f15-efcf-fd22262fd297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.]])\n"
          ]
        }
      ],
      "source": [
        "#There are times when you need 2-d tensors, thus you might need to convert your 1-D tensors to 2-D tensors for using them as inputs\n",
        "a=torch.Tensor([0,1,2,3,4,5])\n",
        "#the first argument of the view method represent the number of rows and second the number of columns \n",
        "a_col = a.view(6,1)\n",
        "#If we didn't know that the original tensor had 6 elements in it, we could use a value of -1\n",
        "aa_col = a.view(-1,1)\n",
        "\n",
        "print(a_col)\n",
        "print(aa_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "400efa5a-9fe2-4933-bb89-211b2e5b46fd",
      "metadata": {
        "id": "400efa5a-9fe2-4933-bb89-211b2e5b46fd"
      },
      "outputs": [],
      "source": [
        "#We can convert a numpy array to a torch tensor using the function \"from numpy\".\n",
        "numpy_array = np.array([0.0,1.0,2.0,3.0,4.0,5.0])\n",
        "torch_tensor = torch.from_numpy(numpy_array)\n",
        "back_tonumpy = torch_tensor.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e485139c-dc89-40e6-ac79-f3f278d6783c",
      "metadata": {
        "id": "e485139c-dc89-40e6-ac79-f3f278d6783c",
        "outputId": "81e691aa-ceeb-4af6-9eb4-2059e0daba95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 2., 3., 4., 5.], dtype=torch.float64)\n",
            "[0. 1. 2. 3. 4. 5.]\n"
          ]
        }
      ],
      "source": [
        "print(torch_tensor)\n",
        "print(back_tonumpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "115fab3d-6a75-4ca0-a71b-9ecbcdb09026",
      "metadata": {
        "id": "115fab3d-6a75-4ca0-a71b-9ecbcdb09026",
        "outputId": "8e086029-93e3-42b7-f587-2be8d1ce0903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    0.1\n",
            "1    1.0\n",
            "2    2.0\n",
            "3    0.3\n",
            "4    4.0\n",
            "5    6.5\n",
            "6    8.7\n",
            "7    9.8\n",
            "dtype: float64\n",
            "tensor([0.1000, 1.0000, 2.0000, 0.3000, 4.0000, 6.5000, 8.7000, 9.8000],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "#Converting pandas series to torch tensor. we can simply use \"values\" to convert series to numpy arrray then it's converted to tensor\n",
        "pandas_series = pd.Series([0.1,1,2,0.3,4,6.5,8.7,9.8])\n",
        "pandas_totorch = torch.from_numpy(pandas_series.values)\n",
        "print(pandas_series)\n",
        "print(pandas_totorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "def97f59-ecb1-4420-9f11-36ec9dace66e",
      "metadata": {
        "id": "def97f59-ecb1-4420-9f11-36ec9dace66e",
        "outputId": "2dfa6594-25c6-4d4e-d276-d8fe79662a66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6]\n"
          ]
        }
      ],
      "source": [
        "#we can us to_list method to return list from tensor\n",
        "this_tensor = torch.tensor([1,2,3,4,5,6])\n",
        "torch_tolist = this_tensor.tolist()\n",
        "print(torch_tolist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc483d6-a63a-4771-8d7a-9c6a7514a441",
      "metadata": {
        "id": "bcc483d6-a63a-4771-8d7a-9c6a7514a441",
        "outputId": "9d95d3a6-8217-45c9-99da-dd9fad22a56f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5)\n",
            "tensor(4)\n"
          ]
        }
      ],
      "source": [
        "new_tensor = torch.tensor([5,3,2,4,7,8])\n",
        "print(new_tensor[0])\n",
        "print(new_tensor[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b249f756-a7eb-4757-8af3-c5bdd1e657c6",
      "metadata": {
        "id": "b249f756-a7eb-4757-8af3-c5bdd1e657c6",
        "outputId": "3b13b26f-27b9-4d0e-fbdb-993fa6caa93d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0, 67, 84,  4,  5,  6,  7,  8])\n",
            "tensor([ 0,  1, 84,  4,  5,  6,  7,  8])\n",
            "tensor([0, 1, 2, 4, 5, 6, 7, 8])\n"
          ]
        }
      ],
      "source": [
        "# we can change the value of the created tensors by specifying the index of it\n",
        "d = torch.tensor([99,67,84,4,5,6,7,8])\n",
        "d[0] = 0\n",
        "print(d)\n",
        "d[1] = 1\n",
        "print(d)\n",
        "d[2] = 2\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ec1b86-10ab-44a3-9b3f-71542bd5693d",
      "metadata": {
        "id": "41ec1b86-10ab-44a3-9b3f-71542bd5693d",
        "outputId": "a6ff52c5-60b3-43a9-9869-e7cbf6103036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 4])\n"
          ]
        }
      ],
      "source": [
        "# we can also assign the elements in the tensor from specififc range to new variable\n",
        "d1 = d[1:4]\n",
        "print(d1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aa773fe-5de8-494e-9f32-6106fc776a2a",
      "metadata": {
        "id": "0aa773fe-5de8-494e-9f32-6106fc776a2a",
        "outputId": "91ff1dbe-a6d9-425c-bf47-16d1851550b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([5., 5., 5., 5.])\n",
            "tensor([4., 6., 6., 4.])\n",
            "tensor([2., 4., 6., 8.])\n"
          ]
        }
      ],
      "source": [
        "#you can also do vector addition in pytorch\n",
        "d2 = torch.tensor([1.0,2.0,3.0,4.0])\n",
        "d3 = torch.tensor([4.0,3.0,2.0,1.0])\n",
        "d4 = d2+d3\n",
        "d5 = d2*d3\n",
        "print(d4)\n",
        "print(d5)\n",
        "#you can directly multiply tensors\n",
        "print(2*d2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d057db9-20d8-420b-94f8-7637716ca292",
      "metadata": {
        "id": "9d057db9-20d8-420b-94f8-7637716ca292",
        "outputId": "e2ff1101-9b4f-4325-cb4e-383cba615e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(130)\n"
          ]
        }
      ],
      "source": [
        "#dot product using tensor\n",
        "u = torch.tensor([1,2,3,4,5])\n",
        "v = torch.tensor([6,7,8,9,10])\n",
        "uv= torch.dot(u,v)\n",
        "print(uv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b37f990f-004d-4d95-9454-be05dba286e3",
      "metadata": {
        "id": "b37f990f-004d-4d95-9454-be05dba286e3",
        "outputId": "8de7e3b2-11c4-40e5-96fe-757b4aa55228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 3, 4, 5, 6])\n"
          ]
        }
      ],
      "source": [
        "#adding constant to the tensor\n",
        "u1 = u+1\n",
        "#it will add the constant value to each element in the tensor\n",
        "print(u1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f1e2f3c-0d42-493f-8966-52e3700e4ad0",
      "metadata": {
        "id": "1f1e2f3c-0d42-493f-8966-52e3700e4ad0",
        "outputId": "5015206e-ae95-4ebe-a8c8-b7431df84b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.5000)\n",
            "tensor(5.)\n",
            "tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "#functions in tensor\n",
        "mean_a = a.mean()\n",
        "print(mean_a)\n",
        "max_a = a.max()\n",
        "print(max_a)\n",
        "min_a = a.min()\n",
        "print(min_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f6c75d5-2987-4828-9ed4-7ed46c7e8904",
      "metadata": {
        "id": "3f6c75d5-2987-4828-9ed4-7ed46c7e8904",
        "outputId": "750282eb-f090-4605-e202-1bf1e7d767a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.0000e+00,  1.0000e+00, -8.7423e-08])\n",
            "tensor([ 1.0000e+00, -4.3711e-08, -1.0000e+00])\n"
          ]
        }
      ],
      "source": [
        "#We can create the following torch tensor in Radians\n",
        "x = torch.tensor([0, np.pi/2, np.pi])\n",
        "y = torch.sin(x)\n",
        "print(y)\n",
        "y1 = torch.cos(x)\n",
        "print(y1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c9d47b-4ee8-48ec-a294-340aff6d79e7",
      "metadata": {
        "id": "85c9d47b-4ee8-48ec-a294-340aff6d79e7",
        "outputId": "9cb5a761-ae2f-4c54-f417-f15c982e0389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-2.0000, -1.5000, -1.0000, -0.5000,  0.0000,  0.5000,  1.0000,  1.5000,\n",
            "         2.0000])\n"
          ]
        }
      ],
      "source": [
        "#linspace returns evenly space numbers over a specified interval\n",
        "aa = torch.linspace(-2,2,steps=9)\n",
        "#we get 9 evenly spaced numbers over the interval from -2 to 2\n",
        "print(aa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d15fc1f5-d41f-4676-8a5b-593fda45895d",
      "metadata": {
        "id": "d15fc1f5-d41f-4676-8a5b-593fda45895d",
        "outputId": "a0059b76-f9cf-4799-8d52-7dcb6e37e5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f470e7a3250>]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x1 = torch.linspace(0, 2*np.pi, 100)\n",
        "y1 = torch.sin(x1)\n",
        "plt.plot(x1.numpy(), y1.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9c9d6dd-6416-4195-965f-a9cf91420e47",
      "metadata": {
        "id": "d9c9d6dd-6416-4195-965f-a9cf91420e47"
      },
      "source": [
        "## 2-D Tensors\n",
        "1. Examples of Two Dimensional tensors \n",
        "2. Tensor Creation in 2D\n",
        "3. Indexing and Slicing of 2D tensors\n",
        "4. Basic operations on 2d tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79233676-db74-4f30-8114-01e3c698a6ec",
      "metadata": {
        "id": "79233676-db74-4f30-8114-01e3c698a6ec"
      },
      "source": [
        "1. In 2D tensors are essentially matrix. Each row of the tensor corresponds to a different sample and each column of the tensor corresponds to a feature or attribute. \n",
        "2. We can also represent gray scale images as 2d tensors. The image intensity values can be represented as numbers between the range 0 to 255.\n",
        "3. 0 corresponds to the color black and 255 corresponds to the white color\n",
        "4. These numerical values are stored as a grid like a database we can store them in a tensor\n",
        "5. Tensors can be extended to any number of dimensions such as 3 dimensions, 4 dimensions and so on.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4b55fbf-f47c-45ad-ba2d-fb2608ef90fe",
      "metadata": {
        "id": "f4b55fbf-f47c-45ad-ba2d-fb2608ef90fe"
      },
      "source": [
        "1. A 3d tensor is essentially a combination of three 1 dimensional tensors\n",
        "2. Consider a color image composed of three color components: blue, green, red.\n",
        "3. Like a gray scale image each color component is made up of different intensity values that can be represent as a tensor.\n",
        "4. This matrix contains the intensity values of the blue channel in the picture.\n",
        "5. Similarly this one has the intensities for the green channel. And this one has intensities for the red channel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a266a4-2f8d-4982-98e0-6d9e060ac06a",
      "metadata": {
        "id": "20a266a4-2f8d-4982-98e0-6d9e060ac06a",
        "outputId": "e7e349fe-e7b3-4c4c-d60b-eea3a2109fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[11, 12, 13, 14],\n",
            "        [21, 22, 23, 24],\n",
            "        [31, 32, 33, 34]])\n"
          ]
        }
      ],
      "source": [
        "#lets create a list that contains 3 nested lists each of equal size\n",
        "ab = [[11,12,13,14],[21,22,23,24],[31,32,33,34]]\n",
        "ab1 = torch.tensor(ab)\n",
        "print(ab1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71639f38-4390-4c27-950e-c35d9ed40ae8",
      "metadata": {
        "id": "71639f38-4390-4c27-950e-c35d9ed40ae8",
        "outputId": "a8140a94-4c14-4feb-958d-e860d06e549a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is dimension value:  2\n",
            "This is the size value:  torch.Size([3, 4])\n",
            "Shape of the tensor is:  torch.Size([3, 4])\n",
            "Number of elements present are:  12\n"
          ]
        }
      ],
      "source": [
        "#we can use ndimension method to obtain the number of dimensions of a torch tensor\n",
        "#the dimension of tensor can also be sometimes refered as it's rank\n",
        "print(\"This is dimension value: \",ab1.ndimension())\n",
        "\n",
        "#the shape attribute of tensor returns the number of rows and columns of the tensor\n",
        "print(\"This is the size value: \",ab1.shape)\n",
        "\n",
        "#we can also use size method to get the shape of tensor\n",
        "print(\"Shape of the tensor is: \",ab1.size())\n",
        "\n",
        "#you can use the numel method to obtain the number of elements present in the tensor\n",
        "print(\"Number of elements present are: \",ab1.numel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1847c53a-5562-48e2-8cc9-6df2ff15afd0",
      "metadata": {
        "id": "1847c53a-5562-48e2-8cc9-6df2ff15afd0",
        "outputId": "761946a7-3cda-4fb9-ea34-cc426064a1b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(14)\n",
            "tensor([13, 23, 33])\n"
          ]
        }
      ],
      "source": [
        "#we can use the rectangular brackets to access the different elements of a tensor\n",
        "#the first index corresponds to the rows and second index corresponds to columns\n",
        "print(ab1[0][3])\n",
        "print(ab1[0:3,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5aec68b-a1da-440d-b3d1-8dc2adc2d970",
      "metadata": {
        "id": "c5aec68b-a1da-440d-b3d1-8dc2adc2d970",
        "outputId": "b1458475-8b07-4878-ea86-fe484e4152cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2,  4, 16, 18],\n",
            "        [ 6,  8, 10, 12]])\n"
          ]
        }
      ],
      "source": [
        "ab2 = torch.tensor([[1,2,8,9],[3,4,5,6]])\n",
        "ab21 = 2*ab2\n",
        "print(ab21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cca9db5-f6b0-4e9c-9631-3d399585d1dd",
      "metadata": {
        "id": "9cca9db5-f6b0-4e9c-9631-3d399585d1dd",
        "outputId": "38ed8780-3b38-4d91-b77b-e78a3296164b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 3,  8],\n",
            "        [12, 26]])\n"
          ]
        }
      ],
      "source": [
        "#matrix multiplication in pytorch can be done by using \"mm\" method\n",
        "#before doing the matrix multiplications we must make sure the number of columns in matrix m1 \n",
        "#must be equal to number of rows in matrix m2\n",
        "m1 = torch.tensor([[0,1,2],[3,4,5]])\n",
        "m2 = torch.tensor([[1,1],[1,2],[1,3]])\n",
        "m3 = torch.mm(m1,m2)\n",
        "print(m3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "823a085f-945d-415e-91c3-2d88bbaef341",
      "metadata": {
        "id": "823a085f-945d-415e-91c3-2d88bbaef341"
      },
      "source": [
        "* Differentiation in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7139739-9e97-4616-a10d-78e973b0b68e",
      "metadata": {
        "id": "a7139739-9e97-4616-a10d-78e973b0b68e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m95",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "d9c9d6dd-6416-4195-965f-a9cf91420e47"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}